{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory of the \"notebooks\" directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do\n",
    "\n",
    "- Parse PDF\n",
    "- Text Splitters\n",
    "- Count Tokens\n",
    "- Use different libraries - langchain\n",
    "- Generate embeddings\n",
    "- Store in Qdrant\n",
    "- Retrieve from Qdrant\n",
    "\n",
    "\n",
    "### Different PDF parsers\n",
    "\n",
    "- `PyMuPDF` is a Python wrapper for the MuPDF library, which is a lightweight PDF and XPS viewer and parser. It can be used to extract text, images, and other data from PDF files, as well as to manipulate PDF files programmatically. It provides a comprehensive set of tools for working with PDF files, including merging and splitting PDFs, adding annotations and bookmarks, and converting PDFs to other formats.\n",
    "\n",
    "- `DeepDocDetection` is a Python library for document analysis and OCR (Optical Character Recognition). It provides tools for detecting text, images, and tables in PDF files, as well as for performing OCR on scanned documents. It uses deep learning models to achieve high accuracy in document analysis and OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the OpenAI API key as an environment variable in your system. In Linux or macOS, you can do this by running the following command in a terminal: \n",
    "\n",
    "`export OPENAI_API_KEY=<your_key_here>`.\n",
    "\n",
    "Restart your Jupyter notebook to ensure the environment variable is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import qdrant_client\n",
    "\n",
    "collection_name = \"langchain_documents\"\n",
    "qdrant_url = \"http://localhost:6333/\"\n",
    "qdrant_port = 6333\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "query = \"What wrappers are provided by SearxNG search API\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval\n",
    "\n",
    "Similarity search\n",
    "The simplest scenario for using Qdrant vector store is to perform a similarity search. Under the hood, our query will be encoded with the embedding_function and used to find similar documents in Qdrant collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qdrant_client.QdrantClient(url=qdrant_url, port=qdrant_port)\n",
    "\n",
    "qdrant = Qdrant(client=client, \n",
    "                collection_name=\"langchain_documents\", \n",
    "                embedding_function=embeddings.embed_query)\n",
    "\n",
    "found_docs = qdrant.similarity_search(query)\n",
    "print(found_docs[0].page_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_docs = qdrant.similarity_search_with_score(query)\n",
    "document, score = found_docs[0]\n",
    "print(document.page_content)\n",
    "print(f\"\\nScore: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "\n",
    "client = QdrantClient(url=qdrant_url)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=openai_api_key)\n",
    "qdrant = Qdrant(client=client, collection_name=collection_name, embedding_function=embeddings.embed_query)\n",
    "search_results = qdrant.similarity_search(query, k=2)\n",
    "chain = load_qa_chain(OpenAI(openai_api_key=openai_api_key,temperature=0.2), chain_type=\"stuff\")\n",
    "results = chain({\"input_documents\": search_results, \"question\": query}, return_only_outputs=True)\n",
    "\n",
    "print(results[\"output_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "659c28ce7e3ad1cd8a0d13fd6d5a8530fe6cc749aa1f817ccd73612dea7b9ea4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
